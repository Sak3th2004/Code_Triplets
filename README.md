# ğŸ“ Intel Unnati 2025 - Image Super-Resolution Project

**Knowledge Distillation for Image Super-Resolution**

## ğŸ“Š Project Overview

This project implements a lightweight image super-resolution model using knowledge distillation techniques as part of the Intel Unnati Industrial Training Program 2025.

### ğŸ¯ Key Achievements

- âœ… **92.7% SSIM Score** (Target: >90%)
- âœ… **483K Parameters** (Lightweight model)
- âœ… **Real-time Processing** up to 1920Ã—1080
- âœ… **Knowledge Distillation** from SwinIR teacher model

## Dataset Used is uploaded in google Drive Link : https://drive.google.com/drive/folders/1S0-4pJsoOoKeGSiSCTVQCso6eTyZbri9?usp=sharing

## ğŸ—ï¸ Project Structure

```
Intel_project_final_version/
â”œâ”€â”€ Intel_Unnati_Project.ipynb    # Main implementation notebook
â”œâ”€â”€ DIV2K_train_HR/                # Dataset (800 high-res images)
â”œâ”€â”€ student_models/                # Trained model weights
â”œâ”€â”€ TeacherModel/                  # SwinIR teacher model
â”œâ”€â”€ data/                          # Processed training data
â”œâ”€â”€ 100_enhanced_results.png       # Visual results
â””â”€â”€ README.md                      # This file
```

## ğŸ”§ Technical Specifications

- **Dataset:** 800 DIV2K high-resolution images
- **Architecture:** Enhanced CNN with 6 residual blocks
- **Training:** Knowledge distillation with L1+MSE loss
- **Performance:** 92.7% average SSIM, 28.5 dB PSNR
- **Scalability:** 100Ã—100 to 1920Ã—1080 resolution

## ğŸ“‹ Requirements

```python
torch>=1.9.0
torchvision>=0.10.0
opencv-python>=4.5.0
scikit-image>=0.18.0
matplotlib>=3.3.0
numpy>=1.21.0
Pillow>=8.3.0
```

## ğŸš€ Usage

1. Open `Intel_Unnati_Project.ipynb` in Jupyter/VS Code
2. Run cells sequentially to:
   - Set up environment
   - Load and preprocess data
   - Train the model
   - Evaluate performance
   - Generate visual results

## ğŸ“ˆ Results

- **SSIM Score:** 92.7% (exceeds 90% target)
- **Model Size:** 1.85 MB
- **PSNR Score:** 28.5 dB (exceeds 25 dB target)
- **Resolution:** 1920Ã—1080 (real-time processing)

- **Model Parameters:** 483K
- **Knowledge Distillation:** Implemented
- **Teacher Model:** SwinIR (Swin Transformer)
- **Success Rate:** 87% of images achieve >90% SSIM

## ğŸ† Intel Unnati Requirements Met

- âœ… Knowledge distillation implementation
- âœ… 100Ã—100 patch training
- âœ… 1920Ã—1080 scalability testing
- âœ… Performance target exceeded
- âœ… Lightweight model achieved

## ğŸ‘¨â€ğŸ’¼ Author

**Team:** Code triplets  
**Program:** Intel Unnati Industrial Training 2025  
**Project:** Knowledge Distillation for Image Super-Resolution

---

_Project Status: âœ… SUCCESSFULLY COMPLETED_
